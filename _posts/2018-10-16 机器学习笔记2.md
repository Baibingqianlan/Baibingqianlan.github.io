---
layout: post
---



### 1.模型评估
----
"错误率" (error rate)：
通常我们把分类错误的样本数占样本总数的比例称为 ，即如果在m 个样本中有α 个样本分类错误，则错误率  E= α/m;

把学习器的实际预测输出与样本的真实输出之间的差异称为"**误差**" (error) ,
学习器在训练集上的误差称为"**训练误差**" (training error)或"**经验误差**" (empirical error) ，在新样本上的误差称为"**泛化误差**" (generalization error).

"**过拟合**" (overfitting)：当学习器把训练样本学得"太
好"了的时候，很可能巳经把训练样本自身的一些特点当作了所有潜在样本都
会具有的一般性质，这样就会导致泛化性能下降这种现象在机器学习中称为. 
"**欠拟合**" (underfitting) ，是指对训练样本的一般性质尚未学好.

若可彻底避免过拟合，则通过经验误差最小化就能获最优解，这就意
味着我们构造性地证明了" P=NP" ;

### 2.评估方法
1. "**留出法**" (hold-out)直接将数据集D划分为两个互斥的集合,其中一个
集合作为训练集S，另一个作为测试集T.在S 上训练出模型后，用T 来评估其测试误差，作为对泛化误差的估计.

2. "**交叉验证法**" (cross validation)先将数据集D 划分为k 个大小相似的互斥子集， 即D = D1 U D2 υ... U Dk, Di n Dj = ø (í ,j ) . 每个子集Di 都尽可能保持数据分布的一致性，即从D 中通过分层采样得到. 然后，每次用
k-1 个子集的并集作为训练集,余下的那个子集作为测试集;这样就可获得k
组训练/测试集，从而可进行k 次训练和测试，最终返回的是这k 个测试结果
的均值。

3. "自助法" (bootstrapping)它直接以自助采样法(bootstrap sampling) 为基础[Efron and Tibshirani, 1993]. 给定包含m 个样
本的数据集D ， 我们对它进行采样产生数据集D': 每次随机从D 中挑选一个
样本，将其拷贝放入D' 然后再将该样本放回初始数据集D 中，使得该样本在
下次采样时仍有可能被采到;这个过程重复执行m 次后，我们就得到了包含m
个样本的数据集D'。可将D' 用作训练集， D\D' 用作测试集;这样实际评估的模型与期望评估的模型都使用m 个训练样本，而我们仍有数据总量约1/3 的没在训
练集中出现的样本用于测试.这样的测试结果，亦称"包外估计" (out-of-bag
estimate).

	优点：自助法在数据集较小、难以有效划分训练/测试集时很有用;此外，自助法
能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处.缺点：自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。

### 3.查准率、查全率

在信息检索中，我们经常会关心"检索出的信息中有多少比例是用户感兴趣的"或者" 用
户感兴趣的信息中有多少被检索出来了”，"查准率"（precision）与"查全率" (recall) 是更为适用于此类需求的性能度量.

![定义]({{site.baseurl}}/assets/2018-10-16/1.bmp)

查准率和查全率是一对矛盾的度量.一般来说，查准率高时，查全率往往
偏低;而查全率高时，查准率往往偏低.例如，若希望将好瓜尽可能多地选出来，
则可通过增加选瓜的数量来实现，如果将所有西瓜都选上，那么所有的好瓜也必然都被选上了，但这样查准率就会较低;若希望选出的瓜中好瓜比例尽可能
高，则可只挑选最有把握的瓜， 但这样就难免会漏掉不少好瓜，使得查全率较
低.通常只有在一些简单任务中7 才可能使查全率和查准率都很高.

以查准率为纵轴、查全率为横轴作图，就得到了查准率-查全率曲线，简称" P-R 曲线"显示该曲线的图称为" P-R图"。

"平衡点" (Break-Event Point，简称BEP)就是这样一个度量，它是" 查
准率=查全率"时的取值。BEP 还是过于简化了些，更常用的是F1 度量:

![定义]({{site.baseurl}}/assets/2018-10-16/2.bmp)

**调和平均数（harmonic mean）**又称倒数平均数，是总体各统计变量倒数的算术平均数的倒数。

调和平均数应用：调和平均数可以用在相同距离但速度不同时，平均速度的计算；如一段路程，前半段时速60公里，后半段时速30公里〔两段距离相等〕，则其平均速度为两者的调和平均数时速40公里。电阻的计算，也用到了调和平均数。

**加权平均值**即将各数值乘以相应的权数，然后加总求和得到总体值，再除以总的单位数。加权平均值的大小不仅取决于总体中各单位的数值（变量值）的大小，而且取决于各数值出现的次数（频数），由于各数值出现的次数对其在平均数中的影响起着权衡轻重的作用，因此叫做权数。

加权平均数中的“权”的表现形式有多种，且由于“权”的变化，其结果就会大相径庭，他的这一特殊性，越来越受到人们的重视，应用也越来越广泛。

### 4.ROC,AUC
ROC 全称是"受试者工作特征" (Receiver Operating Characteristic) 曲
线.
我们根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以它们为横、纵坐标作图'就得到了"ROC 曲线".
ROC 曲线的纵轴是"真正例率" (True Positive Rate，简称TPR) ，横轴是"假正例率" (False PositiveRate，简称FPR).

若两个学习器的ROC 曲线发生交叉，则难以-般性地断言两者孰优孰劣. 此时如果一定要进行比较， 则较为合理的判据是比较ROC 曲线下的面积，即AUC (Area Under
ROC Curve).AUC 可通过对ROC 曲线下各部分的面积求和而得. 假定ROC 曲线是由坐标为{(Xl ， yl), (X2, Y2) , . . . , (xm, Ym)} 的点按序连接而形成(Xl =0, xm = 1) ;


### 5.代价敏感错误率与代价曲线

在现实任务中常会遇到这样的情况:不同类型的错误所造成的后果不同.
例如在医疗诊断中，错误地把患者诊断为健康人与错误地把健康人诊断为患者，
看起来都是犯了"一次错误"但后者的影响是增加了进一步检查的麻烦，前
者的后果却可能是丧失了拯救生命的最佳时机;再如，门禁系统错误地把可通
行人员拦在门外，将使得用户体验不佳，但错误地把陌生人放进门内，则会造成
严重的安全事故.为权衡不同类型错误所造成的不同损失，可为错误赋予"非
均等代价" (unequa1 cost).

在非均等代价下，我们所希望的不再是简单地最小化错误次
数，而是希望最小化"总体代价" (total cost). 

令D+ 与D一分别代表样例集D 的正例子集和反例子
集，则"代价敏感" (cost-sensitive)错误率为


![定义]({{site.baseurl}}/assets/2018-10-16/3.bmp)

![定义]({{site.baseurl}}/assets/2018-10-16/4.bmp)


参考：

1. [my coding.net](http://zhwa3232.coding.me/baibingqianlan.github.io/)
2. [机器学习(周志华西瓜书) 目录+参考答案](https://blog.csdn.net/scythe666/article/details/73017294)
3. [【机器学习】支持向量机SVM原理及推导](https://blog.csdn.net/ljn113399/article/details/69220087)
4. [极大似然估计详解](https://blog.csdn.net/zengxiantao1994/article/details/72787849)
5. [协方差](https://baike.baidu.com/item/%E5%8D%8F%E6%96%B9%E5%B7%AE/2185936?fr=aladdin)
6. [马氏距离](https://baike.baidu.com/item/%E9%A9%AC%E6%B0%8F%E8%B7%9D%E7%A6%BB/8927833?fr=aladdin)
