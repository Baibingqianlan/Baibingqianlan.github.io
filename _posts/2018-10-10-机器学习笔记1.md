---
layout: post
---

了解历史，才能更好把握现在。

### 1.机器学习历史简介
----
机器学习是在计算机上，从数据中产生模型的算法，“学习算法”。

数据－>**算法**->输出模型决策树。


**历史：**摘自周志华的《机器学习》

机器学习是人工智能(artificial intelligence)研究发展到一定阶段的必然产物.

二十世纪五十年代到七十年代初，人工智能研究处于"推理期".这一阶段的代表性工
作主要有A. Newell 和H. Simon 的"逻辑理论家" (Logic Theorist)程序以及
此后的"通用问题求解" (General Problem Solving)程序等，这些工作在当时
取得了令人振奋的结果.

从二十世纪七十年代中期开始，人工智能研究进入了"知识
期"在这一时期，大量专家系统问世，在很多应用领域取得了大量成果.E.A.
Feigenbaum 作为"知识工程"之父在1994 年获得图灵奖.但是，人们逐渐认
识到，专家系统面临"知识工程瓶颈"，简单地说，就是由人来把知识总结出来
再教给计算机是相当困难的.

二十世纪八十年代以来，被研究最多、应用最广的是"从样例中学习" (也就是广义
的归纳学习) ，它涵盖了监督学习、无监督学习等。

在二十世纪八十年代，"从样例中学习"的一大主流是符号主义学习，
其代表包括决策树(decision tree)和基于逻辑的学习.典型的决策树学习以信
息论为基础，以信息娟的最小化为目标，直接模拟了人类对概念进行判定的
树形流程.基于逻辑的学习的著名代表是归纳逻辑程序设计(Inductive Logic
Programming，简称ILP) ，可看作机器学习与逻辑程序设计的交叉，它使用一
阶逻辑(即谓词逻辑)来进行知识表示，通过修改和扩充逻辑表达式(例如Prolog
表达式)来完成对数据的归纳.

二十世纪九十年代中期之前，"从样例中学习"的另一主流技术是基于神
经网络的连接主义学习。1986 年， D. E. Rumelhart 等人重
新发明了著名的BP 算法，产生了深远影响.与符号主义学习能产生明确的概
念表示不同，连接主义学习产生的是"黑箱"模型，因此从知识获取的角度来
看?连接主义学习技术有明显弱点;然而，由于有BP 这样有效的算法，使得它
可以在很多现实问题上发挥作用.事实上， BP 一直是被应用得最广泛的机器
学习算法之一.连接主义学习的最大局限是其"试错性'p; 简单地说?其学习过
程涉及大量参数，而参数的设置缺乏理论指导，主要靠于工"调参"夸张一点
说，参数调节上失之毫厘，学习结果可能谬以千里.

二十世纪九十年代中期"统计学习" (statistical learning) 闪亮登场并
迅速占据主流舞台，代表性技术是支持向量机(Support Vector Machine，简称
SVM) 以及更一般的"核方法" (kernel methods).例如V. N. Vapnik 在1963 年提出了"支持向量"概念，他和A. J.
Chervonenkis 在1968 年提出VC 维，在1974 年提出了结构风险最小化原则等.
但直到九十年代中期统计学习才开始成为机器学习的主流，一方面是由于有效
的支持向量机算法在九十年代初才被提出，其优越性能到九十年代中期在文
本分类应用中才得以显现;另一方面，正是在连接主义学习技术的局限性凸显
之后，人们才把目光转向了以统计学习理论为直接支撑的统计学习技术.

二十一世纪初，连接主义学习又卷土重来，掀起了以"深度学习"为名的热潮.所谓深度学习，狭义地说就是"很多层"的神经网络.在若干测试和竞赛上，尤其是涉及语音、图像等复杂对象的应用中，深度学习技术取得了优越性能.以往机器学习技术在应用中要取得好性能，对使用者的要求较高;而深度学习技术涉及的模型复杂度非常高，以至于只要下工夫"调参把参数调节好，性能往往就好.因此，深度学习虽缺乏严格的理论基础，但它显
著降低了机器学习应用者的门槛，为机器学习技术走向工程实践带来了便利.

随着科学研究的基本手段从传统的"理论十实验"走向现在的
"理论+实验十计算"，乃至出现"数据科学"这样的提法，机器学习的重要
性日趋显著，因为"计算"的目的往往是数据分析，而数据科学的核心也恰是
通过分析数据来获得价值.

2006 年，卡耐基梅隆大学宣告成立世界上第一个"机器学习系"，机器学
习领域奠基人之- T. Mitchell 教授出任首任系主任. 2012 年3 月7 美国奥巴马
政府启动"大数据研究与发展计划"，美国国家科学基金会旋即在加州大学伯
克利分校启动加强计划，强调要深入研究和整合大数据时代的三大关键技术:
机器学习、云计算、众包(crowdsourcing) .

数据挖掘领域在二十世纪九十年代形成，它受到很多学科领域的影响，其中数据库、机器学习、统计学无疑影响最大[Zhou， 2003]. 数据挖掘是从海量数据中发掘知识，这就必然涉及对"海量数据"的管理和分析.**大体来说，数据库领域的研究为数据挖掘提供数据管
理技术，而机器学习和统计学的研究为数据挖掘提供数据分析技术**.由于统计
学界的研究成果通常需要经由机器学习研究来形成有效的学习算法，之后再进
入数据挖掘领域，因此从这个意义上说，统计学主要是通过机器学习对数据挖
掘发挥影响，而机器学习领域和数据库领域则是数据挖掘的两大支撑.

**关键技术与规则**：决策树学习，版本空间，规则学习，奥卡姆剃刀原则，多释原则等

奥卡姆剃刀原则主张选择与经验观察一致的**最简单**假设，它在自然科学如
物理学、天文学等领域中是一个广为沿用的基础性原则。

古希腊哲学家伊壁坞鲁(公元前341年一前270年)提出的"多释原则" (principle of multipleexplanations) ，主张保留与经验观察一致的所有假设[Asmis ， 1984]，这与集成学习(ensemble learning) 方面的研究更加吻合.

### 2.重要会议与期刊：

机器学习领域最重要的国际学术会议是国际机器学习会议(ICML) 、国际
神经信息处理系统会议(NIPS)和国际学习理论会议(COLT) ，重要的区域性会
议主要有欧洲机器学习会议(ECML)和亚洲机器学习会议(ACML); 最重要的
国际学术期刊是Journal of Machine Learning Research 和Machine Learning.

人工智能领域的重要会议如IJCAI、AAAI 以及重要期刊如Art侨c归1 Intelligence、Journal of Art听cial Intelligence Reseαrch， 数据挖掘领域的重要会议如KDD 、ICDM 以及重要期刊如ACM Transactions on Knowledge Discovery fromDα归、Dαtα Mining and Knowledge Discovery.

计算机视觉与模式识别领域的重要会议如CVPR 以及重要期刊如IEEE ransactions on Pattem Analysis and Machine Intelligence. 

神经网络领域的重要期刊如Neural Computation、IEEE Transaιtions on Neural Networks αηd Leαming 8ystems 等也经常发表机器学习方面的论文.

统计学领域的重要期刊如Annals 8tαtistics 等也常有关于统计学习方面的理论文章发表.

国内不少书籍包含机器学习方面的内容，例如[陆汝铃， 1996]. [李航， 2012]
是以统计学习为主题的读物.国内机器学习领域最主要的活动是两年一次
的中国机器学习大会(CCML) 以及每年举行的"机器学习及其应用"研讨
会(MLA); 很多学术刊物都经常刊登有关机器学习的论文.



参考：

1. [my coding.net](http://zhwa3232.coding.me/baibingqianlan.github.io/)
2. [机器学习(周志华西瓜书) 目录+参考答案](https://blog.csdn.net/scythe666/article/details/73017294)
3. [【机器学习】支持向量机SVM原理及推导](https://blog.csdn.net/ljn113399/article/details/69220087)
