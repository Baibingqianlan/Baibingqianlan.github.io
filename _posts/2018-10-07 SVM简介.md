---
layout: post
---

### SVM的背景简介
----
支持向量机(Support Vector Machine)是Cortes和Vapnik于1995年首先提出的，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中.

Vapnik是统计机器学习的大牛，他出版的《Statistical Learning Theory》是一本完整阐述统计机器学习思想的名著。在该书中详细的论证了统计机器学习之所以区别于传统机器学习的本质，就在于统计机器学习能够精确的给出学习效果，能够解答需要的样本数等等一系列问题。与统计机器学习的精密思维相比，传统的机器学习基本上属于摸着石头过河，用传统的机器学习方法构造分类系统完全成了一种技巧，一个人做的结果可能很好，另一个人差不多的方法做出来却很差，缺乏指导和原则。

所谓VC维是对函数类的一种度量，可以简单的理解为问题的复杂程度，VC维越高，一个问题就越复杂。正是因为SVM关注的是VC维，后面我们可以看到，SVM解决问题的时候，和样本的维数是无关的（甚至样本是上万维的都可以，这使得SVM很适合用来解决文本分类的问题，当然，有这样的能力也因为引入了核函数）.

SVM的思想，目的就是找到一个超平面，将数据点都正确地分在超平面的两侧。那么，又怎么表示这个“都正确”呢？可以这样考虑：就是让那些“很有可能不正确”的数据点彼此分开得明显一点就可以了。对于其它“不那么可能不正确”或者说“一看就很正确”的数据点，就可以不用管了。这也是SVM名称的由来，模型是由那些支持向量（Support Vector）决定的。这也是为什么SVM对outlier不敏感s。








参考：

1. [my coding.net](http://zhwa3232.coding.me/baibingqianlan.github.io/)
2. [SVM-支持向量机算法概述 ---一篇非常深入浅出介绍SVM的文章](https://blog.csdn.net/ljn113399/article/details/69220087)
3. [【机器学习】支持向量机SVM原理及推导](https://blog.csdn.net/ljn113399/article/details/69220087)
